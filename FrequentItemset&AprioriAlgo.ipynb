{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rules Analysis\n",
    "\n",
    "**Association Rules Analysis** is a data mining technique that finds interesting relationships or patterns in large datasets. It is commonly used in **market basket analysis** to discover product associations, but it also applies to many fields, such as recommendation systems, fraud detection, and healthcare.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Concepts in Association Rules Analysis\n",
    "\n",
    "### 1. **Frequent Itemsets**\n",
    "\n",
    "A **frequent itemset** is a set of items that appear together frequently in transactions. To find frequent itemsets, a user specifies a **minimum support threshold** that determines the minimum frequency an itemset must appear to be considered \"frequent.\"\n",
    "\n",
    "For example, in a grocery store, if 10% of transactions contain both bread and butter, and the minimum support threshold is set to 5%, then $\\{ \\text{bread, butter} \\}$ would be considered a **frequent itemset**.\n",
    "\n",
    "Frequent itemsets are essential for generating **association rules**, which help identify relationships between items.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Apriori Algorithm**\n",
    "\n",
    "The **Apriori Algorithm** is a classic algorithm used to find frequent itemsets and generate association rules. It uses a **bottom-up** approach, where frequent itemsets are generated level by level (starting with single items and then extending to larger itemsets).\n",
    "\n",
    "### Steps in the Apriori Algorithm:\n",
    "1. **Find frequent itemsets**: \n",
    "   - Start by identifying all frequent 1-itemsets (itemsets containing a single item that meets the minimum support threshold).\n",
    "   - Extend to 2-itemsets, 3-itemsets, and so on by combining smaller frequent itemsets.\n",
    "2. **Generate association rules**: \n",
    "   - Once frequent itemsets are identified, generate rules of the form $X \\Rightarrow Y$, where $X$ and $Y$ are itemsets.\n",
    "\n",
    "### Key Principle: **Apriori Property**\n",
    "The Apriori Algorithm relies on the **Apriori Property**, which states that:\n",
    "- **If an itemset is frequent, all its subsets must also be frequent**.\n",
    "  \n",
    "This property reduces the search space, as any itemset that contains an infrequent subset is pruned from consideration.\n",
    "\n",
    "### Example:\n",
    "1. Consider a dataset where we have the following transactions:\n",
    "   - Transaction 1: $\\{ \\text{bread, milk} \\}$\n",
    "   - Transaction 2: $\\{ \\text{bread, butter, milk} \\}$\n",
    "   - Transaction 3: $\\{ \\text{butter, eggs} \\}$\n",
    "   - Transaction 4: $\\{ \\text{bread, butter} \\}$\n",
    "   - Transaction 5: $\\{ \\text{bread, eggs, milk} \\}$\n",
    "   \n",
    "   If we set a minimum support threshold of 2 transactions (40%), the Apriori Algorithm will first find frequent 1-itemsets, then extend to 2-itemsets, and so on.\n",
    "\n",
    "### Advantages of Apriori:\n",
    "- Simple to implement.\n",
    "- Intuitive approach for finding frequent itemsets.\n",
    "\n",
    "### Limitations of Apriori:\n",
    "- Computationally expensive for large datasets due to the need to scan the dataset multiple times.\n",
    "- The number of candidate itemsets grows exponentially as the size of the itemset increases, leading to inefficiency.\n",
    "\n",
    "## Metrics for Association Rule Evaluation\n",
    "\n",
    "### 1. **Support**\n",
    "Support measures how frequently an itemset appears in the dataset:\n",
    "$$\n",
    "\\text{Support}(X) = \\frac{\\text{Number of transactions containing } X}{\\text{Total number of transactions}}\n",
    "$$\n",
    "\n",
    "### 2. **Confidence**\n",
    "Confidence measures how often the rule $X \\Rightarrow Y$ holds, given that $X$ has occurred:\n",
    "$$\n",
    "\\text{Confidence}(X \\Rightarrow Y) = \\frac{\\text{Support}(X \\cup Y)}{\\text{Support}(X)}\n",
    "$$\n",
    "\n",
    "### 3. **Lift**\n",
    "Lift measures how much more likely $X$ and $Y$ co-occur than if they were independent:\n",
    "$$\n",
    "\\text{Lift}(X \\Rightarrow Y) = \\frac{\\text{Support}(X \\cup Y)}{\\text{Support}(X) \\times \\text{Support}(Y)}\n",
    "$$\n",
    "- If $\\text{Lift} > 1$, $X$ and $Y$ are positively correlated.\n",
    "- If $\\text{Lift} = 1$, $X$ and $Y$ are independent.\n",
    "- If $\\text{Lift} < 1$, $X$ and $Y$ are negatively correlated.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Frequent Itemsets** are sets of items that appear frequently together in transactions.\n",
    "- **Apriori Algorithm** uses candidate generation and pruning to find frequent itemsets, but can be slow for large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from mlxtend) (1.14.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from mlxtend) (2.1.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 9.5 MB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess the Dataset\n",
    "For this tutorial, we'll use a sample dataset representing transactions (e.g., purchases in a store). Each transaction is represented as a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bread  Butter   Eggs   Milk\n",
      "0   True   False   True   True\n",
      "1   True    True   True  False\n",
      "2  False   False   True   True\n",
      "3   True    True   True   True\n",
      "4   True   False  False   True\n",
      "5   True   False   True  False\n",
      "6   True    True  False   True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Sample dataset (list of transactions)\n",
    "dataset = [\n",
    "    ['Milk', 'Bread', 'Eggs'],\n",
    "    ['Bread', 'Eggs', 'Butter'],\n",
    "    ['Milk', 'Eggs'],\n",
    "    ['Milk', 'Bread', 'Eggs', 'Butter'],\n",
    "    ['Milk', 'Bread'],\n",
    "    ['Bread', 'Eggs'],\n",
    "    ['Milk', 'Bread', 'Butter'],\n",
    "]\n",
    "\n",
    "# Convert the dataset into a one-hot encoded format\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Frequent Itemset Mining using Apriori\n",
    "Now, we'll use the Apriori algorithm to mine frequent itemsets from the one-hot encoded dataset based on a minimum support threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    support         itemsets\n",
      "0  0.857143          (Bread)\n",
      "1  0.428571         (Butter)\n",
      "2  0.714286           (Eggs)\n",
      "3  0.714286           (Milk)\n",
      "4  0.428571  (Bread, Butter)\n",
      "5  0.571429    (Bread, Eggs)\n",
      "6  0.571429    (Bread, Milk)\n",
      "7  0.428571     (Eggs, Milk)\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Define the minimum support threshold (e.g., 0.4 means an itemset must appear in at least 40% of transactions)\n",
    "min_support = 0.4\n",
    "\n",
    "# Perform frequent itemset mining using Apriori\n",
    "frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "\n",
    "print(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Association Rules\n",
    "Next, we'll use the frequent itemsets to generate association rules and calculate various association metrics such as confidence and lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules:\n",
      "  antecedents consequents   support  confidence      lift\n",
      "0    (Butter)     (Bread)  0.428571    1.000000  1.166667\n",
      "1     (Bread)      (Eggs)  0.571429    0.666667  0.933333\n",
      "2      (Eggs)     (Bread)  0.571429    0.800000  0.933333\n",
      "3     (Bread)      (Milk)  0.571429    0.666667  0.933333\n",
      "4      (Milk)     (Bread)  0.571429    0.800000  0.933333\n",
      "5      (Eggs)      (Milk)  0.428571    0.600000  0.840000\n",
      "6      (Milk)      (Eggs)  0.428571    0.600000  0.840000\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "# Generate association rules with minimum confidence threshold (e.g., 0.6)\n",
    "min_confidence = 0.6\n",
    "association_rules_df = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(association_rules_df[['antecedents', 'consequents', 'support', 'confidence','lift']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and Interpret the Results\n",
    "The output will be a DataFrame containing frequent itemsets, their corresponding support values, and the length of each itemset. The support value represents the percentage of transactions in which the itemset appears.\n",
    "\n",
    "You can analyze and interpret the results to identify the most frequent itemsets and their support. These frequent itemsets represent the combinations of items that appear frequently in the transactions and can provide valuable insights into item co-occurrences.\n",
    "\n",
    "In this tutorial, we demonstrated how to recognize frequent itemsets based on a minimum support threshold using the Apriori algorithm in Python. You can adjust the min_support threshold to obtain more or fewer frequent itemsets based on your specific use case.\n",
    "\n",
    "Frequent itemset mining is a powerful technique for identifying interesting associations between items in transactional data and can be applied to various domains, such as market basket analysis, customer behavior analysis, and recommendation systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
